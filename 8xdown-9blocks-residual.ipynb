{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from generator import CityScapesGenerator\n",
    "from model_residual import create_model\n",
    "from loss import focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 1024, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 512, 64) 1728        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256, 512, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 512, 64) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 256, 128 73728       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 256, 128 512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 128, 256, 128 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 128, 256) 294912      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 128, 256) 1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 128, 256) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 128, 256) 65792       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 128, 256) 1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 64, 128, 256) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_6 (Dep (None, 64, 128, 1024 12288       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 64, 128, 1024 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 128, 256) 262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 128, 256) 1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 64, 128, 256) 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 128, 256) 0           activation_26[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 128, 256) 65792       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 64, 128, 256) 1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 64, 128, 256) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_7 (Dep (None, 64, 128, 1024 12288       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64, 128, 1024 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 128, 256) 262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 128, 256) 1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 128, 256) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 128, 256) 0           activation_29[0][0]              \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 128, 256) 65792       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 128, 256) 1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 128, 256) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_8 (Dep (None, 64, 128, 1024 12288       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64, 128, 1024 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 128, 256) 262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 128, 256) 1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 64, 128, 256) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 128, 256) 0           activation_32[0][0]              \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 128, 256) 65792       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 128, 256) 1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 64, 128, 256) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_9 (Dep (None, 64, 128, 1024 12288       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 64, 128, 1024 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 128, 256) 262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 128, 256) 1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 128, 256) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 128, 256) 0           activation_35[0][0]              \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 128, 256) 65792       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 64, 128, 256) 1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 64, 128, 256) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_10 (De (None, 64, 128, 1024 12288       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 64, 128, 1024 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 128, 256) 262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 64, 128, 256) 1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 64, 128, 256) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 128, 256) 0           activation_38[0][0]              \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 128, 256) 65792       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 64, 128, 256) 1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 64, 128, 256) 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_11 (De (None, 64, 128, 1024 12288       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 64, 128, 1024 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 128, 256) 262400      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 64, 128, 256) 1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 64, 128, 256) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 64, 128, 256) 0           activation_41[0][0]              \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 128, 256) 65792       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 64, 128, 256) 1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 64, 128, 256) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_12 (De (None, 64, 128, 1024 12288       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 64, 128, 1024 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 128, 256) 262400      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 64, 128, 256) 1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 64, 128, 256) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 128, 256) 0           activation_44[0][0]              \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 128, 256) 65792       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 64, 128, 256) 1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 64, 128, 256) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_13 (De (None, 64, 128, 1024 12288       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 64, 128, 1024 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 128, 256) 262400      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 64, 128, 256) 1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 64, 128, 256) 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 64, 128, 256) 0           activation_47[0][0]              \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 128, 256) 65792       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 64, 128, 256) 1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 64, 128, 256) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_14 (De (None, 64, 128, 1024 12288       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 64, 128, 1024 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 128, 256) 262400      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 64, 128, 256) 1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 64, 128, 256) 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 64, 128, 256) 0           activation_50[0][0]              \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 128, 19)  4883        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 512, 1024, 19 0           conv2d_37[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,496,659\n",
      "Trainable params: 3,468,115\n",
      "Non-trainable params: 28,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model((512, 1024, 3), width=64, depth=9)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "bs = 4\n",
    "\n",
    "gen_train = CityScapesGenerator('train', dir_='data', batch_size=bs)\n",
    "gen_val = CityScapesGenerator('val', dir_='data', batch_size=bs, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.PolynomialDecay(\n",
    "    0.01, \n",
    "    len(gen_train) * epochs, \n",
    "    1e-4, \n",
    "    0.9\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr_schedule),\n",
    "    loss=focal_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 744 steps, validate for 125 steps\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 5193s 7s/step - loss: 0.0564 - val_loss: 0.0724\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0302 - val_loss: 0.0526\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 5183s 7s/step - loss: 0.0271 - val_loss: 0.0397\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 5186s 7s/step - loss: 0.0235 - val_loss: 0.0435\n",
      "Epoch 5/100\n",
      "744/744 [==============================] - 5165s 7s/step - loss: 0.0205 - val_loss: 0.0361\n",
      "Epoch 6/100\n",
      "744/744 [==============================] - 5169s 7s/step - loss: 0.0197 - val_loss: 0.0388\n",
      "Epoch 7/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0186 - val_loss: 0.0225\n",
      "Epoch 8/100\n",
      "744/744 [==============================] - 5182s 7s/step - loss: 0.0168 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "744/744 [==============================] - 5182s 7s/step - loss: 0.0165 - val_loss: 0.0470\n",
      "Epoch 10/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0158 - val_loss: 0.0297\n",
      "Epoch 11/100\n",
      "744/744 [==============================] - 5179s 7s/step - loss: 0.0149 - val_loss: 0.0184\n",
      "Epoch 12/100\n",
      "744/744 [==============================] - 5190s 7s/step - loss: 0.0144 - val_loss: 0.0242\n",
      "Epoch 13/100\n",
      "744/744 [==============================] - 5183s 7s/step - loss: 0.0150 - val_loss: 0.0194\n",
      "Epoch 14/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0139 - val_loss: 0.0608\n",
      "Epoch 15/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0138 - val_loss: 0.0201\n",
      "Epoch 16/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0134 - val_loss: 0.0548\n",
      "Epoch 17/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0129 - val_loss: 0.0175\n",
      "Epoch 18/100\n",
      "744/744 [==============================] - 5171s 7s/step - loss: 0.0122 - val_loss: 0.0217\n",
      "Epoch 19/100\n",
      "744/744 [==============================] - 5169s 7s/step - loss: 0.0123 - val_loss: 0.0398\n",
      "Epoch 20/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0124 - val_loss: 0.0238\n",
      "Epoch 21/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 22/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0117 - val_loss: 0.0215\n",
      "Epoch 23/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0113 - val_loss: 0.0278\n",
      "Epoch 24/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0113 - val_loss: 0.0173\n",
      "Epoch 25/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0116 - val_loss: 0.0825\n",
      "Epoch 26/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0106 - val_loss: 0.0171\n",
      "Epoch 27/100\n",
      "744/744 [==============================] - 5176s 7s/step - loss: 0.0106 - val_loss: 0.0159\n",
      "Epoch 28/100\n",
      "744/744 [==============================] - 5176s 7s/step - loss: 0.0108 - val_loss: 0.0601\n",
      "Epoch 29/100\n",
      "744/744 [==============================] - 5176s 7s/step - loss: 0.0107 - val_loss: 0.0152\n",
      "Epoch 30/100\n",
      "744/744 [==============================] - 5206s 7s/step - loss: 0.0104 - val_loss: 0.0173\n",
      "Epoch 31/100\n",
      "744/744 [==============================] - 5187s 7s/step - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 32/100\n",
      "744/744 [==============================] - 5186s 7s/step - loss: 0.0101 - val_loss: 0.0252\n",
      "Epoch 33/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0101 - val_loss: 0.0143\n",
      "Epoch 34/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0098 - val_loss: 0.0177\n",
      "Epoch 35/100\n",
      "744/744 [==============================] - 5170s 7s/step - loss: 0.0098 - val_loss: 0.0141\n",
      "Epoch 36/100\n",
      "744/744 [==============================] - 5174s 7s/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 37/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0095 - val_loss: 0.0135\n",
      "Epoch 38/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 39/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0090 - val_loss: 0.0141\n",
      "Epoch 40/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 41/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0095 - val_loss: 0.0230\n",
      "Epoch 42/100\n",
      "744/744 [==============================] - 5182s 7s/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 43/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0089 - val_loss: 0.0123\n",
      "Epoch 44/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0089 - val_loss: 0.0191\n",
      "Epoch 45/100\n",
      "744/744 [==============================] - 5169s 7s/step - loss: 0.0087 - val_loss: 0.0240\n",
      "Epoch 46/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0087 - val_loss: 0.0174\n",
      "Epoch 47/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 48/100\n",
      "744/744 [==============================] - 5247s 7s/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 49/100\n",
      " 56/744 [=>............................] - ETA: 1:18:34 - loss: 0.0089"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    gen_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=gen_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 744 steps, validate for 125 steps\n",
      "Epoch 64/100\n",
      "744/744 [==============================] - 5243s 7s/step - loss: 0.0074 - val_loss: 0.0136\n",
      "Epoch 65/100\n",
      "744/744 [==============================] - 5245s 7s/step - loss: 0.0074 - val_loss: 0.0137\n",
      "Epoch 66/100\n",
      "744/744 [==============================] - 5235s 7s/step - loss: 0.0071 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "744/744 [==============================] - 5233s 7s/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 68/100\n",
      "744/744 [==============================] - 5235s 7s/step - loss: 0.0071 - val_loss: 0.0133\n",
      "Epoch 69/100\n",
      "744/744 [==============================] - 5230s 7s/step - loss: 0.0071 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "744/744 [==============================] - 5227s 7s/step - loss: 0.0070 - val_loss: 0.0113\n",
      "Epoch 71/100\n",
      "744/744 [==============================] - 5229s 7s/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 72/100\n",
      "744/744 [==============================] - 5227s 7s/step - loss: 0.0072 - val_loss: 0.0144\n",
      "Epoch 73/100\n",
      "744/744 [==============================] - 5226s 7s/step - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 74/100\n",
      "744/744 [==============================] - 5223s 7s/step - loss: 0.0068 - val_loss: 0.0127\n",
      "Epoch 75/100\n",
      "744/744 [==============================] - 5219s 7s/step - loss: 0.0066 - val_loss: 0.1010\n",
      "Epoch 76/100\n",
      "744/744 [==============================] - 5224s 7s/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 77/100\n",
      "744/744 [==============================] - 5222s 7s/step - loss: 0.0067 - val_loss: 0.0111\n",
      "Epoch 78/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 79/100\n",
      "744/744 [==============================] - 5174s 7s/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 80/100\n",
      "744/744 [==============================] - 5201s 7s/step - loss: 0.0065 - val_loss: 0.0100\n",
      "Epoch 81/100\n",
      "744/744 [==============================] - 5221s 7s/step - loss: 0.0065 - val_loss: 0.0124\n",
      "Epoch 82/100\n",
      "744/744 [==============================] - 5232s 7s/step - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 83/100\n",
      "744/744 [==============================] - 5205s 7s/step - loss: 0.0063 - val_loss: 0.0098\n",
      "Epoch 84/100\n",
      "744/744 [==============================] - 5198s 7s/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 85/100\n",
      "744/744 [==============================] - 5182s 7s/step - loss: 0.0062 - val_loss: 0.0126\n",
      "Epoch 86/100\n",
      "744/744 [==============================] - 5179s 7s/step - loss: 0.0062 - val_loss: 0.0103\n",
      "Epoch 87/100\n",
      "744/744 [==============================] - 5189s 7s/step - loss: 0.0064 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "744/744 [==============================] - 5194s 7s/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 89/100\n",
      "744/744 [==============================] - 5190s 7s/step - loss: 0.0061 - val_loss: 0.0102\n",
      "Epoch 90/100\n",
      "744/744 [==============================] - 5190s 7s/step - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 91/100\n",
      "744/744 [==============================] - 5189s 7s/step - loss: 0.0060 - val_loss: 0.0094\n",
      "Epoch 92/100\n",
      "744/744 [==============================] - 5189s 7s/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 93/100\n",
      "744/744 [==============================] - 5186s 7s/step - loss: 0.0058 - val_loss: 0.0096\n",
      "Epoch 94/100\n",
      "744/744 [==============================] - 5168s 7s/step - loss: 0.0059 - val_loss: 0.0087\n",
      "Epoch 95/100\n",
      "744/744 [==============================] - 5165s 7s/step - loss: 0.0057 - val_loss: 0.0098\n",
      "Epoch 96/100\n",
      "744/744 [==============================] - 5166s 7s/step - loss: 0.0057 - val_loss: 0.0084\n",
      "Epoch 97/100\n",
      "744/744 [==============================] - 5212s 7s/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 98/100\n",
      "744/744 [==============================] - 5172s 7s/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 99/100\n",
      "744/744 [==============================] - 5175s 7s/step - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 100/100\n",
      "744/744 [==============================] - 5166s 7s/step - loss: 0.0057 - val_loss: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f031c2e8668>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    gen_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=gen_val,\n",
    "    initial_epoch=63,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/model_residual_64_9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f031c65f518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot dilation rate histograms\n",
    "fig, axs = plt.subplots(2, 9, figsize=(25, 5))\n",
    "plt.xlabel('dr')\n",
    "axs1 = iter(axs[0])\n",
    "axs2 = iter(axs[1])\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) == 4 and not isinstance(layer, keras.layers.BatchNormalization):\n",
    "        ax = next(axs1)\n",
    "        ax.hist(weights[2].flatten())\n",
    "        ax.set_xlabel('dr')\n",
    "        ax = next(axs2)\n",
    "        ax.hist(weights[3].flatten())\n",
    "        ax.set_xlabel('dr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f77a860d320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred = model.predict(gen_train[0][0])\n",
    "\n",
    "plt.imshow(pred[0, ..., 1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add SRIP regularization to 1x1 convs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "\n",
    "gen_train = CityScapesGenerator('train', dir_ = 'data', batch_size=bs)\n",
    "gen_val = CityScapesGenerator('val', dir_ = 'data', batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\t0.193\n",
      "0.00103\t0.0554\n",
      "0.00106\t0.0605\n",
      "0.00109\t0.0493\n",
      "0.00112\t0.036\n",
      "0.00116\t0.0228\n",
      "0.00119\t0.0149\n",
      "0.00122\t0.0108\n",
      "0.00126\t0.0087\n",
      "0.0013\t0.00777\n",
      "0.00134\t0.00698\n",
      "0.00137\t0.00626\n",
      "0.00141\t0.00584\n",
      "0.00146\t0.00529\n",
      "0.0015\t0.00483\n",
      "0.00154\t0.00456\n",
      "0.00159\t0.00426\n",
      "0.00163\t0.00403\n",
      "0.00168\t0.00371\n",
      "0.00173\t0.00344\n",
      "0.00178\t0.00325\n",
      "0.00183\t0.00305\n",
      "0.00189\t0.0029\n",
      "0.00194\t0.00277\n",
      "0.002\t0.00258\n",
      "0.00206\t0.00242\n",
      "0.00212\t0.00231\n",
      "0.00218\t0.00219\n",
      "0.00225\t0.00207\n",
      "0.00231\t0.00194\n",
      "0.00238\t0.00182\n",
      "0.00245\t0.00172\n",
      "0.00252\t0.00168\n",
      "0.0026\t0.00173\n",
      "0.00267\t0.00168\n",
      "0.00275\t0.00166\n",
      "0.00283\t0.00156\n",
      "0.00291\t0.00155\n",
      "0.003\t0.00163\n",
      "0.00309\t0.00267\n",
      "0.00318\t0.00354\n",
      "0.00327\t0.00281\n",
      "0.00337\t0.00255\n",
      "0.00347\t0.00231\n",
      "0.00357\t0.00238\n",
      "0.00367\t0.00213\n",
      "0.00378\t0.00211\n",
      "0.00389\t0.00188\n",
      "0.004\t0.00183\n",
      "0.00412\t0.00162\n",
      "0.00424\t0.00166\n",
      "0.00437\t0.00148\n",
      "0.00449\t0.00163\n",
      "0.00463\t0.00159\n",
      "0.00476\t0.00164\n",
      "0.0049\t0.00149\n",
      "0.00505\t0.00152\n",
      "0.00519\t0.00138\n",
      "0.00535\t0.00126\n",
      "0.0055\t0.00127\n",
      "0.00566\t0.00124\n",
      "0.00583\t0.00113\n",
      "0.006\t0.00115\n",
      "0.00618\t0.00109\n",
      "0.00636\t0.00108\n",
      "0.00654\t0.00109\n",
      "0.00674\t0.00101\n",
      "0.00693\t0.00117\n",
      "0.00714\t0.00104\n",
      "0.00735\t0.00103\n",
      "0.00756\t0.000926\n",
      "0.00778\t0.00103\n",
      "0.00801\t0.00106\n",
      "0.00825\t0.00117\n",
      "0.00849\t0.00105\n",
      "0.00874\t0.00106\n",
      "0.00899\t0.00107\n",
      "0.00926\t0.00169\n",
      "0.00953\t0.00195\n",
      "0.00981\t0.00208\n",
      "0.0101\t0.00203\n",
      "0.0104\t0.002\n",
      "0.0107\t0.00158\n",
      "0.011\t0.0019\n",
      "0.0113\t0.00191\n",
      "0.0117\t0.00214\n",
      "0.012\t0.00191\n",
      "0.0124\t0.00173\n",
      "0.0127\t0.00168\n",
      "0.0131\t0.00161\n",
      "0.0135\t0.00149\n",
      "0.0139\t0.0015\n",
      "0.0143\t0.00145\n",
      "0.0147\t0.0013\n",
      "0.0151\t0.00127\n",
      "0.0156\t0.00112\n",
      "0.016\t0.00126\n",
      "0.0165\t0.00135\n",
      "0.017\t0.00117\n",
      "0.0175\t0.00121\n",
      "0.018\t0.00129\n",
      "0.0185\t0.00125\n",
      "0.0191\t0.00212\n",
      "0.0196\t0.00356\n",
      "0.0202\t0.00718\n",
      "0.0208\t0.00922\n",
      "0.0214\t0.0752\n",
      "0.022\t0.0575\n",
      "0.0227\t0.0808\n",
      "0.0233\t0.142\n",
      "0.024\t0.0992\n",
      "0.0247\t0.0632\n",
      "0.0255\t0.084\n",
      "0.0262\t0.0493\n",
      "0.027\t0.0462\n",
      "0.0278\t0.0409\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-aefac11b8c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{lr:.3g}\\t{loss:.3g}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m         standalone=True)\n\u001b[0m\u001b[1;32m    984\u001b[0m     outputs = (\n\u001b[1;32m    985\u001b[0m         outputs['total_loss'] + outputs['output_losses'] + outputs['metrics'])\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m   \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   1961\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[1;32m   1963\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y = gen_train[0]\n",
    "\n",
    "for lr in np.logspace(-3, 0, 240):\n",
    "    K.set_value(model.optimizer.lr, lr)\n",
    "    loss = model.train_on_batch(x, y)\n",
    "    print(f'{lr:.3g}\\t{loss:.3g}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

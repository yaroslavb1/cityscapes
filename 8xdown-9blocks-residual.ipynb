{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from generator import CityScapesGenerator\n",
    "from model_residual import create_model\n",
    "from loss import focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 1024, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 512, 64) 1728        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256, 512, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 512, 64) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 256, 128 73728       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 256, 128 512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 128, 256, 128 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 128, 256) 294912      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 128, 256) 1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 128, 256) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 128, 256) 65792       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 128, 256) 1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 64, 128, 256) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_6 (Dep (None, 64, 128, 1024 12288       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 64, 128, 1024 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 128, 256) 262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 128, 256) 1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 64, 128, 256) 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 128, 256) 0           activation_26[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 128, 256) 65792       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 64, 128, 256) 1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 64, 128, 256) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_7 (Dep (None, 64, 128, 1024 12288       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64, 128, 1024 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 128, 256) 262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 128, 256) 1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 128, 256) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 128, 256) 0           activation_29[0][0]              \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 128, 256) 65792       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 128, 256) 1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 128, 256) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_8 (Dep (None, 64, 128, 1024 12288       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 64, 128, 1024 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 128, 256) 262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 128, 256) 1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 64, 128, 256) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 128, 256) 0           activation_32[0][0]              \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 128, 256) 65792       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 128, 256) 1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 64, 128, 256) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_9 (Dep (None, 64, 128, 1024 12288       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 64, 128, 1024 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 128, 256) 262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 128, 256) 1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 128, 256) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 128, 256) 0           activation_35[0][0]              \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 128, 256) 65792       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 64, 128, 256) 1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 64, 128, 256) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_10 (De (None, 64, 128, 1024 12288       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 64, 128, 1024 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 128, 256) 262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 64, 128, 256) 1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 64, 128, 256) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 128, 256) 0           activation_38[0][0]              \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 128, 256) 65792       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 64, 128, 256) 1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 64, 128, 256) 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_11 (De (None, 64, 128, 1024 12288       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 64, 128, 1024 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 128, 256) 262400      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 64, 128, 256) 1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 64, 128, 256) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 64, 128, 256) 0           activation_41[0][0]              \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 128, 256) 65792       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 64, 128, 256) 1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 64, 128, 256) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_12 (De (None, 64, 128, 1024 12288       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 64, 128, 1024 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 128, 256) 262400      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 64, 128, 256) 1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 64, 128, 256) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 128, 256) 0           activation_44[0][0]              \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 128, 256) 65792       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 64, 128, 256) 1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 64, 128, 256) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_13 (De (None, 64, 128, 1024 12288       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 64, 128, 1024 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 128, 256) 262400      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 64, 128, 256) 1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 64, 128, 256) 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 64, 128, 256) 0           activation_47[0][0]              \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 128, 256) 65792       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 64, 128, 256) 1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 64, 128, 256) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_context_conv2d_14 (De (None, 64, 128, 1024 12288       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 64, 128, 1024 4096        depthwise_context_conv2d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 64, 128, 1024 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 128, 256) 262400      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 64, 128, 256) 1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 64, 128, 256) 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 64, 128, 256) 0           activation_50[0][0]              \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 128, 19)  4883        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 512, 1024, 19 0           conv2d_37[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,496,659\n",
      "Trainable params: 3,468,115\n",
      "Non-trainable params: 28,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model((512, 1024, 3), width=64, depth=9)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "bs = 4\n",
    "\n",
    "gen_train = CityScapesGenerator('train', dir_ = 'data', batch_size=bs)\n",
    "gen_val = CityScapesGenerator('val', dir_ = 'data', batch_size=bs, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.PolynomialDecay(\n",
    "    0.01, \n",
    "    len(gen_train) * epochs, \n",
    "    1e-4, \n",
    "    0.9\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr_schedule),\n",
    "    loss=focal_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 744 steps, validate for 125 steps\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 5193s 7s/step - loss: 0.0564 - val_loss: 0.0724\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0302 - val_loss: 0.0526\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 5183s 7s/step - loss: 0.0271 - val_loss: 0.0397\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 5186s 7s/step - loss: 0.0235 - val_loss: 0.0435\n",
      "Epoch 5/100\n",
      "744/744 [==============================] - 5165s 7s/step - loss: 0.0205 - val_loss: 0.0361\n",
      "Epoch 6/100\n",
      "744/744 [==============================] - 5169s 7s/step - loss: 0.0197 - val_loss: 0.0388\n",
      "Epoch 7/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0186 - val_loss: 0.0225\n",
      "Epoch 8/100\n",
      "744/744 [==============================] - 5182s 7s/step - loss: 0.0168 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "744/744 [==============================] - 5182s 7s/step - loss: 0.0165 - val_loss: 0.0470\n",
      "Epoch 10/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0158 - val_loss: 0.0297\n",
      "Epoch 11/100\n",
      "744/744 [==============================] - 5179s 7s/step - loss: 0.0149 - val_loss: 0.0184\n",
      "Epoch 12/100\n",
      "744/744 [==============================] - 5190s 7s/step - loss: 0.0144 - val_loss: 0.0242\n",
      "Epoch 13/100\n",
      "744/744 [==============================] - 5183s 7s/step - loss: 0.0150 - val_loss: 0.0194\n",
      "Epoch 14/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0139 - val_loss: 0.0608\n",
      "Epoch 15/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0138 - val_loss: 0.0201\n",
      "Epoch 16/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0134 - val_loss: 0.0548\n",
      "Epoch 17/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0129 - val_loss: 0.0175\n",
      "Epoch 18/100\n",
      "744/744 [==============================] - 5171s 7s/step - loss: 0.0122 - val_loss: 0.0217\n",
      "Epoch 19/100\n",
      "744/744 [==============================] - 5169s 7s/step - loss: 0.0123 - val_loss: 0.0398\n",
      "Epoch 20/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0124 - val_loss: 0.0238\n",
      "Epoch 21/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 22/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0117 - val_loss: 0.0215\n",
      "Epoch 23/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0113 - val_loss: 0.0278\n",
      "Epoch 24/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0113 - val_loss: 0.0173\n",
      "Epoch 25/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0116 - val_loss: 0.0825\n",
      "Epoch 26/100\n",
      "744/744 [==============================] - 5177s 7s/step - loss: 0.0106 - val_loss: 0.0171\n",
      "Epoch 27/100\n",
      "744/744 [==============================] - 5176s 7s/step - loss: 0.0106 - val_loss: 0.0159\n",
      "Epoch 28/100\n",
      "744/744 [==============================] - 5176s 7s/step - loss: 0.0108 - val_loss: 0.0601\n",
      "Epoch 29/100\n",
      "744/744 [==============================] - 5176s 7s/step - loss: 0.0107 - val_loss: 0.0152\n",
      "Epoch 30/100\n",
      "744/744 [==============================] - 5206s 7s/step - loss: 0.0104 - val_loss: 0.0173\n",
      "Epoch 31/100\n",
      "744/744 [==============================] - 5187s 7s/step - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 32/100\n",
      "744/744 [==============================] - 5186s 7s/step - loss: 0.0101 - val_loss: 0.0252\n",
      "Epoch 33/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0101 - val_loss: 0.0143\n",
      "Epoch 34/100\n",
      "744/744 [==============================] - 5185s 7s/step - loss: 0.0098 - val_loss: 0.0177\n",
      "Epoch 35/100\n",
      "744/744 [==============================] - 5170s 7s/step - loss: 0.0098 - val_loss: 0.0141\n",
      "Epoch 36/100\n",
      "744/744 [==============================] - 5174s 7s/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 37/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0095 - val_loss: 0.0135\n",
      "Epoch 38/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 39/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0090 - val_loss: 0.0141\n",
      "Epoch 40/100\n",
      "744/744 [==============================] - 5180s 7s/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 41/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0095 - val_loss: 0.0230\n",
      "Epoch 42/100\n",
      "744/744 [==============================] - 5182s 7s/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 43/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0089 - val_loss: 0.0123\n",
      "Epoch 44/100\n",
      "744/744 [==============================] - 5178s 7s/step - loss: 0.0089 - val_loss: 0.0191\n",
      "Epoch 45/100\n",
      "744/744 [==============================] - 5169s 7s/step - loss: 0.0087 - val_loss: 0.0240\n",
      "Epoch 46/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0087 - val_loss: 0.0174\n",
      "Epoch 47/100\n",
      "744/744 [==============================] - 5181s 7s/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 48/100\n",
      "744/744 [==============================] - 5247s 7s/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 49/100\n",
      " 56/744 [=>............................] - ETA: 1:18:34 - loss: 0.0089"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    gen_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=gen_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 744 steps, validate for 125 steps\n",
      "Epoch 64/100\n",
      "744/744 [==============================] - 5243s 7s/step - loss: 0.0074 - val_loss: 0.0136\n",
      "Epoch 65/100\n",
      "744/744 [==============================] - 5245s 7s/step - loss: 0.0074 - val_loss: 0.0137\n",
      "Epoch 66/100\n",
      "744/744 [==============================] - 5235s 7s/step - loss: 0.0071 - val_loss: 0.0117\n",
      "Epoch 67/100\n",
      "744/744 [==============================] - 5233s 7s/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 68/100\n",
      "744/744 [==============================] - 5235s 7s/step - loss: 0.0071 - val_loss: 0.0133\n",
      "Epoch 69/100\n",
      "744/744 [==============================] - 5230s 7s/step - loss: 0.0071 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "744/744 [==============================] - 5227s 7s/step - loss: 0.0070 - val_loss: 0.0113\n",
      "Epoch 71/100\n",
      "744/744 [==============================] - 5229s 7s/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 72/100\n",
      "370/744 [=============>................] - ETA: 42:44 - loss: 0.0076"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    gen_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=gen_val,\n",
    "    initial_epoch=63,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('temp1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f032c648f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot dilation rate histograms\n",
    "fig, axs = plt.subplots(2, 9, figsize=(25, 5))\n",
    "plt.xlabel('dr')\n",
    "axs1 = iter(axs[0])\n",
    "axs2 = iter(axs[1])\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) == 4 and not isinstance(layer, keras.layers.BatchNormalization):\n",
    "        ax = next(axs1)\n",
    "        ax.hist(weights[2].flatten())\n",
    "        ax.set_xlabel('dr')\n",
    "        ax = next(axs2)\n",
    "        ax.hist(weights[3].flatten())\n",
    "        ax.set_xlabel('dr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f77a860d320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred = model.predict(gen_train[0][0])\n",
    "\n",
    "plt.imshow(pred[0, ..., 1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add SRIP regularization to 1x1 convs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "\n",
    "gen_train = CityScapesGenerator('train', dir_ = 'data', batch_size=bs)\n",
    "gen_val = CityScapesGenerator('val', dir_ = 'data', batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\t0.193\n",
      "0.00103\t0.0554\n",
      "0.00106\t0.0605\n",
      "0.00109\t0.0493\n",
      "0.00112\t0.036\n",
      "0.00116\t0.0228\n",
      "0.00119\t0.0149\n",
      "0.00122\t0.0108\n",
      "0.00126\t0.0087\n",
      "0.0013\t0.00777\n",
      "0.00134\t0.00698\n",
      "0.00137\t0.00626\n",
      "0.00141\t0.00584\n",
      "0.00146\t0.00529\n",
      "0.0015\t0.00483\n",
      "0.00154\t0.00456\n",
      "0.00159\t0.00426\n",
      "0.00163\t0.00403\n",
      "0.00168\t0.00371\n",
      "0.00173\t0.00344\n",
      "0.00178\t0.00325\n",
      "0.00183\t0.00305\n",
      "0.00189\t0.0029\n",
      "0.00194\t0.00277\n",
      "0.002\t0.00258\n",
      "0.00206\t0.00242\n",
      "0.00212\t0.00231\n",
      "0.00218\t0.00219\n",
      "0.00225\t0.00207\n",
      "0.00231\t0.00194\n",
      "0.00238\t0.00182\n",
      "0.00245\t0.00172\n",
      "0.00252\t0.00168\n",
      "0.0026\t0.00173\n",
      "0.00267\t0.00168\n",
      "0.00275\t0.00166\n",
      "0.00283\t0.00156\n",
      "0.00291\t0.00155\n",
      "0.003\t0.00163\n",
      "0.00309\t0.00267\n",
      "0.00318\t0.00354\n",
      "0.00327\t0.00281\n",
      "0.00337\t0.00255\n",
      "0.00347\t0.00231\n",
      "0.00357\t0.00238\n",
      "0.00367\t0.00213\n",
      "0.00378\t0.00211\n",
      "0.00389\t0.00188\n",
      "0.004\t0.00183\n",
      "0.00412\t0.00162\n",
      "0.00424\t0.00166\n",
      "0.00437\t0.00148\n",
      "0.00449\t0.00163\n",
      "0.00463\t0.00159\n",
      "0.00476\t0.00164\n",
      "0.0049\t0.00149\n",
      "0.00505\t0.00152\n",
      "0.00519\t0.00138\n",
      "0.00535\t0.00126\n",
      "0.0055\t0.00127\n",
      "0.00566\t0.00124\n",
      "0.00583\t0.00113\n",
      "0.006\t0.00115\n",
      "0.00618\t0.00109\n",
      "0.00636\t0.00108\n",
      "0.00654\t0.00109\n",
      "0.00674\t0.00101\n",
      "0.00693\t0.00117\n",
      "0.00714\t0.00104\n",
      "0.00735\t0.00103\n",
      "0.00756\t0.000926\n",
      "0.00778\t0.00103\n",
      "0.00801\t0.00106\n",
      "0.00825\t0.00117\n",
      "0.00849\t0.00105\n",
      "0.00874\t0.00106\n",
      "0.00899\t0.00107\n",
      "0.00926\t0.00169\n",
      "0.00953\t0.00195\n",
      "0.00981\t0.00208\n",
      "0.0101\t0.00203\n",
      "0.0104\t0.002\n",
      "0.0107\t0.00158\n",
      "0.011\t0.0019\n",
      "0.0113\t0.00191\n",
      "0.0117\t0.00214\n",
      "0.012\t0.00191\n",
      "0.0124\t0.00173\n",
      "0.0127\t0.00168\n",
      "0.0131\t0.00161\n",
      "0.0135\t0.00149\n",
      "0.0139\t0.0015\n",
      "0.0143\t0.00145\n",
      "0.0147\t0.0013\n",
      "0.0151\t0.00127\n",
      "0.0156\t0.00112\n",
      "0.016\t0.00126\n",
      "0.0165\t0.00135\n",
      "0.017\t0.00117\n",
      "0.0175\t0.00121\n",
      "0.018\t0.00129\n",
      "0.0185\t0.00125\n",
      "0.0191\t0.00212\n",
      "0.0196\t0.00356\n",
      "0.0202\t0.00718\n",
      "0.0208\t0.00922\n",
      "0.0214\t0.0752\n",
      "0.022\t0.0575\n",
      "0.0227\t0.0808\n",
      "0.0233\t0.142\n",
      "0.024\t0.0992\n",
      "0.0247\t0.0632\n",
      "0.0255\t0.084\n",
      "0.0262\t0.0493\n",
      "0.027\t0.0462\n",
      "0.0278\t0.0409\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-aefac11b8c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{lr:.3g}\\t{loss:.3g}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m         standalone=True)\n\u001b[0m\u001b[1;32m    984\u001b[0m     outputs = (\n\u001b[1;32m    985\u001b[0m         outputs['total_loss'] + outputs['output_losses'] + outputs['metrics'])\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m   \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/slavo/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   1961\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[1;32m   1963\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y = gen_train[0]\n",
    "\n",
    "for lr in np.logspace(-3, 0, 240):\n",
    "    K.set_value(model.optimizer.lr, lr)\n",
    "    loss = model.train_on_batch(x, y)\n",
    "    print(f'{lr:.3g}\\t{loss:.3g}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
